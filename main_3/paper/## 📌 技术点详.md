## ğŸ“Œ æŠ€æœ¯ç‚¹è¯¦è§£ä¸å¯è½åœ°æ”¹è¿›å»ºè®®

---

### **1. Attentionæœºåˆ¶æ›¿æ¢ï¼šä»SEåˆ°Triplet Attention**

#### ğŸ” åŸå› ï¼š

EfficientNet ä¸­çš„ SEï¼ˆSqueeze-and-Excitationï¼‰æ¨¡å—ä»…åœ¨â€œé€šé“ç»´åº¦â€ä¸Šå»ºæ¨¡å…¨å±€ä¾èµ–ï¼ˆå³é€šè¿‡ `avg_pool â†’ FC â†’ sigmoid â†’ é€é€šé“åŠ æƒ`ï¼‰ï¼Œ**å¿½ç•¥äº†ç©ºé—´ç»´åº¦çº¹ç†åˆ†å¸ƒ**ï¼Œåœ¨çº¹ç†ç»†èŠ‚ä¸°å¯Œçš„å²©çŸ³å›¾åƒåˆ†ç±»ä¸­æ˜“ä¸¢å¤±å…³é”®ä¿¡æ¯ã€‚

#### âœ… Triplet Attention ä¼˜åŠ¿ï¼š

Triplet Attention æ¨¡å—ä»ä¸‰ä¸ªä¸åŒè§’åº¦**ç¼–ç ç©ºé—´æ³¨æ„åŠ›**ï¼š

* **H Ã— C è§†è§’**ï¼ˆé€šé“â€“é«˜åº¦ï¼‰ï¼Œå…³æ³¨ç«–å‘ç»“æ„ï¼ˆå¦‚è£‚çº¹ã€å±‚ç†ï¼‰
* **W Ã— C è§†è§’**ï¼ˆé€šé“â€“å®½åº¦ï¼‰ï¼Œå…³æ³¨æ¨ªå‘ç»“æ„
* **H Ã— W è§†è§’**ï¼ˆç©ºé—´ç»´åº¦ï¼‰ï¼Œä¿ç•™çº¹ç†æ•´ä½“ä½ç½®æ„Ÿ

æ¯ä¸€åˆ†æ”¯åªä½¿ç”¨äº†ä¸€ä¸ª `Conv2d(1â†’1)` å’Œ BNï¼Œè½»é‡ä½†æœ‰æ•ˆã€‚

#### ğŸ”§ ä½ è¯¥å¦‚ä½•åšï¼š

* **æŸ¥æ‰¾ EfficientNet ä¸­å« SE çš„ blockï¼ˆå¦‚ MBConvBlockï¼‰**
* **å°† `block.se` æ›¿æ¢ä¸º `TripletAttention(kernel_size=7)`**
* **æ— éœ€æ”¹åŠ¨ä¸»å¹²ç»“æ„ï¼Œä¿è¯å¯åŠ è½½ ImageNet é¢„è®­ç»ƒæƒé‡**

ğŸ“Œ **è¡¥å……å»ºè®®**ï¼š

* è‹¥ä¸ç¡®å®šæ¨¡å‹ä¸­ SE çš„ä½ç½®ï¼Œå¯æ‰“å° `model.features` æˆ–å‚è€ƒ PyTorch å®˜æ–¹æºç ç»“æ„ï¼š[torchvision.models.efficientnet.EfficientNet](https://pytorch.org/vision/stable/_modules/torchvision/models/efficientnet.html)

---

### **2. æ•°æ®å¢å¼ºç­–ç•¥ï¼šä»å‡ ä½•æ‰°åŠ¨åˆ°æ³¨æ„åŠ›å¼•å¯¼æ··åˆ**

#### ğŸ” é—®é¢˜ï¼š

ä½ å½“å‰çš„æ•°æ®å¢å¼ºç­–ç•¥ä»…åŒ…å« resizeã€cropã€normalizeï¼Œå±äº**é™æ€å¢å¼º**ï¼Œæ¨¡å‹æ— æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çœ‹åˆ°è¶³å¤Ÿâ€œå˜å¼‚â€çš„å²©çŸ³çº¹ç†å˜åŒ–ã€‚

#### âœ… è®ºæ–‡å¯å‘ï¼š

* ä»–ä»¬ä½¿ç”¨äº† **RandomHorizontalFlip, RandomRotation, ColorJitter** ç­‰è½»é‡æ‰°åŠ¨ï¼›
* è¿˜ç»“åˆ **MixUp** æé«˜ç±»åˆ«è¾¹ç•Œæ³›åŒ–ï¼Œ**é˜²æ­¢æ¨¡å‹å¯¹è®­ç»ƒé›†ä¸­æŸç±»ç‰¹å¾â€œè®°æ­»â€**ã€‚

#### ğŸ”§ ä½ è¯¥å¦‚ä½•åšï¼š

* åœ¨è®­ç»ƒ transform ä¸­åŠ å…¥ï¼š
  
  ```python
  transforms.RandomRotation(15),
  transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
  transforms.RandomHorizontalFlip()
  ```
* MixUp å¯é€šè¿‡è®­ç»ƒå¾ªç¯å®ç°ï¼š
  
  ```python
  def mixup_data(x, y, alpha=0.4):
      lam = np.random.beta(alpha, alpha)
      index = torch.randperm(x.size(0)).to(x.device)
      mixed_x = lam * x + (1 - lam) * x[index, :]
      y_a, y_b = y, y[index]
      return mixed_x, y_a, y_b, lam
  
  def mixup_criterion(criterion, pred, y_a, y_b, lam):
      return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)
  ```

---

### **3. å¾®è°ƒç­–ç•¥ï¼šå†»ç»“éƒ¨åˆ†ä¸»å¹²ã€åˆ†é˜¶æ®µä¼˜åŒ–**

#### ğŸ” é—®é¢˜ï¼š

ä½ å½“å‰æ˜¯ç›´æ¥ fine-tune å…¨éƒ¨å‚æ•°ï¼Œå¯¼è‡´ï¼š

* è®­ç»ƒåˆæœŸä¸ç¨³å®šï¼›
* ç‰¹å¾æå–å™¨å¯èƒ½è¢«ç ´åï¼Œå°¤å…¶åœ¨å°æ•°æ®é›†æˆ–å™ªå£°å¤šçš„æƒ…å†µä¸‹ã€‚

#### âœ… è®ºæ–‡ç­–ç•¥ï¼š

* **å‰è‹¥å¹²å±‚å†»ç»“ï¼ˆå¦‚å‰4å±‚ MBConvï¼‰**ï¼Œåªè®­ç»ƒ headï¼›
* è‹¥æ•°æ®é‡è¾ƒå¤šï¼Œå†é€æ­¥è§£å†» backboneã€‚

#### ğŸ”§ ä½ è¯¥å¦‚ä½•åšï¼š

```python
# å†»ç»“å‰å‡ å±‚ï¼ˆå¦‚ features[0]â€“[3]ï¼‰
for layer in model.features[:4]:
    for param in layer.parameters():
        param.requires_grad = False

# æˆ–è®¾ç½®ä¸åŒ learning rate
optimizer = torch.optim.AdamW([
    {'params': model.features.parameters(), 'lr': 1e-4},
    {'params': model.classifier.parameters(), 'lr': 1e-3}
])
```

---

### **4. è®­ç»ƒè°ƒåº¦ä¸ç›‘æ§ï¼šåŠ¨æ€è°ƒåº¦ + æå‰åœæ­¢**

#### ğŸ” é—®é¢˜ï¼š

ä½ çš„ `scheduler.step()` æ”¾åœ¨è®­ç»ƒåæ‰§è¡Œï¼Œ**æœªå¯¹æ¨¡å‹è¿›è¡ŒåŠ¨æ€è°ƒèŠ‚**ï¼›è€Œ `EarlyStopping` ç›¸å…³ä»£ç è¢«æ³¨é‡Šã€‚

#### âœ… å»ºè®®è°ƒåº¦ï¼š

* ä½¿ç”¨ `ReduceLROnPlateau` æ ¹æ®éªŒè¯é›† loss è‡ªåŠ¨è¡°å‡ï¼›
* åŠ å…¥ `early_stopping(val_loss)` åˆ¤å®šæ˜¯å¦æå‰ç»ˆæ­¢ã€‚

#### ğŸ”§ ç¤ºä¾‹ï¼š

```python
scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)

# æ¯è½®è®­ç»ƒåæ‰§è¡Œ
scheduler.step(val_loss)

# æ—©åœç¤ºä¾‹
early_stopping = EarlyStopping(patience=7, verbose=True)
if early_stopping(val_loss, model):
    break
```

---

### **5. å¯è§†åŒ–åˆ†æä¸åˆ†ç±»è¯¯å·®æ’æŸ¥**

#### âœ… å¢åŠ ï¼š

* **Grad-CAM å¯è§†åŒ–**å…³æ³¨åŒºåŸŸï¼Œç¡®ä¿æ¨¡å‹å…³æ³¨å²©çŸ³çº¹ç†è€ŒéèƒŒæ™¯ï¼›
* **æ··æ·†çŸ©é˜µ + TSNE åˆ†å¸ƒå›¾**å®šä½æ˜“æ··ç±»åˆ«ï¼›
* **ä¿å­˜é”™è¯¯æ ·æœ¬å›¾åƒ**ï¼Œäººå·¥æ£€æŸ¥å…¶ç‰¹å¾åˆ†å¸ƒæˆ–æ•°æ®æ ‡æ³¨é”™è¯¯ã€‚

#### ğŸ”§ ç¤ºä¾‹ï¼š

```python
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# å‡è®¾ preds, labels å·²æ”¶é›†
cm = confusion_matrix(labels, preds)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
```

---

## âœ… æ€»ç»“ï¼šæ”¹è¿›å»ºè®®ä¸€è§ˆè¡¨

| æ–¹é¢        | å½“å‰æƒ…å†µ               | å»ºè®®æ–¹æ¡ˆ                                 |
| --------- | ------------------ | ------------------------------------ |
| Attention | SE                 | æ›¿æ¢ä¸º Triplet Attentionï¼ˆé€šé“+ç©ºé—´ä¸‰ç»´ï¼‰       |
| æ•°æ®å¢å¼º      | Resize + Normalize | åŠ å…¥æ—‹è½¬/è‰²å½©æ‰°åŠ¨ + MixUp                    |
| æ¨¡å‹è°ƒåº¦      | CosineLRï¼Œå•æ­¥æ›´æ–°      | æ”¹ä¸º ReduceLROnPlateau + EarlyStopping |
| å¾®è°ƒæ–¹å¼      | å…¨å‚æ•°æ›´æ–°              | å†»ç»“å‰å‡ å±‚ï¼Œåˆ†ç»„å­¦ä¹ ç‡å¾®è°ƒ                        |
| å¯è§†åŒ–åˆ†æ     | æ—                   | åŠ å…¥ Grad-CAMã€æ··æ·†çŸ©é˜µã€TSNE                |
| è¯„ä¼°æŒ‡æ ‡      | accã€loss           | åŠ å…¥ F1-scoreã€precisionã€recallã€AUC     |



